{
 "metadata": {
  "name": "",
  "signature": "sha256:b1a18ce433ac9fb9286e4f6fb9c46a04ecb2d85f23a49102639de0b95225e76e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time, requests"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we'll just repeat what we did last time to make sure we have all our ducks (erm files) lined up. Its a good idea to split each analysis stage up separately and write out files,so that you are (a) generally working with local files and (b) can restart when some part of the process goes wrong from an intermediate point and not have to fetch data again...."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "URLSTART=\"https://www.goodreads.com\"\n",
      "BESTBOOKS=\"/list/show/1.Best_Books_Ever?page=\"\n",
      "for i in xrange(1,3):\n",
      "    bookpage=str(i)\n",
      "    stuff=requests.get(URLSTART+BESTBOOKS+bookpage)\n",
      "    filetowrite=\"page\"+ '%02d' % i + \".html\"\n",
      "    print \"FTW\", filetowrite\n",
      "    fd=open(filetowrite,\"w\")\n",
      "    fd.write(stuff.text.encode('utf-8'))\n",
      "    fd.close()\n",
      "    time.sleep(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FTW page01.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " page02.html\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyquery import PyQuery as pq\n",
      "bookdict={}\n",
      "for i in xrange(1,3):\n",
      "    books=[]\n",
      "    stri = '%02d' % i\n",
      "    filetoread=\"page\"+ stri + '.html'\n",
      "    print \"FTW\", filetoread\n",
      "    d=pq(filename=filetoread)\n",
      "    for e in d('.bookTitle'):\n",
      "        books.append(pq(e).attr.href)\n",
      "    print books[:10]\n",
      "    bookdict[stri]=books\n",
      "    fd=open(\"list\"+stri+\".txt\",\"w\")\n",
      "    fd.write(\"\\n\".join(books))\n",
      "    fd.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FTW page01.html\n",
        "['/book/show/2767052-the-hunger-games', '/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix', '/book/show/41865.Twilight', '/book/show/2657.To_Kill_a_Mockingbird', '/book/show/1885.Pride_and_Prejudice', '/book/show/18405.Gone_with_the_Wind', '/book/show/11127.The_Chronicles_of_Narnia', '/book/show/7613.Animal_Farm', '/book/show/370493.The_Giving_Tree', '/book/show/11.The_Hitchhiker_s_Guide_to_the_Galaxy']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "FTW page02.html\n",
        "['/book/show/24583.The_Adventures_of_Tom_Sawyer', '/book/show/34.The_Fellowship_of_the_Ring', '/book/show/6310.Charlie_and_the_Chocolate_Factory', '/book/show/4948.The_Very_Hungry_Caterpillar', '/book/show/9717.The_Unbearable_Lightness_of_Being', '/book/show/6900.Tuesdays_with_Morrie', '/book/show/1423.The_Compleat_Works_of_Wllm_Shkspr', '/book/show/12296.The_Scarlet_Letter', '/book/show/10365.Where_the_Red_Fern_Grows', '/book/show/256008.Lonesome_Dove']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok so now lets dive in and get one of these these files and parse them. Lets go get the Tom Sayer url."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tomurl=URLSTART+bookdict['02'][0]\n",
      "tomurl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "'https://www.goodreads.com/book/show/24583.The_Adventures_of_Tom_Sawyer'"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tomstuff=requests.get(tomurl)\n",
      "tomstuff.status_code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "200"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tomstuff.text[:2000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "u'<!DOCTYPE html>\\n<html class=\"desktop\">\\n\\n\\n<head prefix=\"og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# good_reads: http://ogp.me/ns/fb/good_reads#\">\\n  <meta name=\"google-site-verification\" content=\"PfFjeZ9OK1RrUrKlmAPn_iZJ_vgHaZO1YQ-QlG2VsJs\" />\\n\\n  <title>The Adventures of Tom Sawyer by Mark Twain \\u2014 Reviews, Discussion, Bookclubs, Lists</title>\\n    <meta property=\"og:title\" content=\"The Adventures of Tom Sawyer\"/>\\n  <meta property=\"og:type\"  content=\"good_reads:book\"/>\\n  <meta property=\"og:url\" content=\"https://www.goodreads.com/work/best_book/41326609-the-adventures-of-tom-sawyer\"/>\\n  <meta property=\"og:site_name\" content=\"Goodreads\"/>\\n  <meta property=\"og:image\" content=\"https://p.gr-assets.com/max_square/fill/books/1404811979/24583.jpg\"/>\\n  <meta property=\"fb:app_id\" content=\"2415071772\"/>\\n  <meta property=\"og:description\" content=\"From the famous episodes of the whitewashed fence and the ordeal in the cave to the trial of Injun Joe, The Adventures of Tom Sawyer is r...\"/>\\n  <meta property=\"good_reads:isbn\" content=\"0143039563\">\\n  <meta property=\"good_reads:page_num\" content=\"231\">\\n  <meta property=\"good_reads:author\" content=\"https://www.goodreads.com/author/show/1244.Mark_Twain\">\\n    <meta property=\"al:ios:url\" content=\"com.goodreads.https://book/show/24583\">\\n    <meta property=\"al:ios:app_store_id\" content=\"355833469\">\\n    <meta property=\"al:ios:app_name\" content=\"Goodreads\">\\n\\n  <link rel=\"alternate\" href=\"android-app://com.goodreads/https/www.goodreads.com/book/show/24583.The_Adventures_of_Tom_Sawyer\">\\n\\n\\n\\n    <meta name=\"description\" content=\"The Adventures of Tom Sawyer has 392,025 ratings and 4,500 reviews. Nataliya said: I was five and a half years old when my mother gave me The Adventures ...\">\\n\\n  <meta name=\"verify-v1\" content=\"cEf8XOH0pulh1aYQeZ1gkXHsQ3dMPSyIGGYqmF53690=\">\\n  <meta name=\"apple-itunes-app\" content=\"app-id=355833469\">\\n\\n\\n\\n          <script type=\"text/javascript\">\\n        if (window.Mobvious === undefined) {\\n          window.Mobvious = {};\\n  '"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets get everything we want..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d=pq(tomstuff.text)\n",
      "print d(\"meta[property='og:title']\").attr('content')\n",
      "print d(\"meta[property='good_reads:isbn']\").attr('content')\n",
      "print d(\"meta[property='og:type']\").attr('content')\n",
      "print d(\"meta[property='good_reads:author']\").attr('content')\n",
      "print d(\"span.average\").text()\n",
      "print d(\"span.value-title[itemprop='ratingCount']\").attr(\"title\")\n",
      "print d(\"span.value-title[itemprop!='ratingCount']\").attr(\"title\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The Adventures of Tom Sawyer\n",
        "0143039563\n",
        "good_reads:book\n",
        "https://www.goodreads.com/author/show/1244.Mark_Twain\n",
        "3.86\n",
        "392025\n",
        "4500\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now that we know what to do, lets wrap our fetching into a proper script. So that we dont overwhelm their servers, we will only fetch 5 from each page, but you get the idea..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fetched=[]\n",
      "for i in xrange(1,3):\n",
      "    stri = '%02d' % i\n",
      "    with open(\"list\"+stri+\".txt\") as fd:\n",
      "        counter=0\n",
      "        for bookurl_line in fd:\n",
      "            if counter > 4:\n",
      "                break\n",
      "            bookurl=bookurl_line.strip()\n",
      "            if stuff.status_code==200:\n",
      "                stuff=requests.get(URLSTART+bookurl)\n",
      "                filetowrite=bookurl.split('/')[-1]\n",
      "                filetowrite=stri+\"_\"+filetowrite+\".html\"\n",
      "                print \"FTW\", filetowrite\n",
      "                fd=open(filetowrite,\"w\")\n",
      "                fd.write(stuff.text.encode('utf-8'))\n",
      "                fd.close()\n",
      "                fetched.append(filetowrite)\n",
      "            time.sleep(2)\n",
      "            counter=counter+1\n",
      "            \n",
      "print fetched"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FTW 01_2767052-the-hunger-games.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_2.Harry_Potter_and_the_Order_of_the_Phoenix.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_41865.Twilight.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_2657.To_Kill_a_Mockingbird.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_1885.Pride_and_Prejudice.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_24583.The_Adventures_of_Tom_Sawyer.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_34.The_Fellowship_of_the_Ring.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_6310.Charlie_and_the_Chocolate_Factory.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_4948.The_Very_Hungry_Caterpillar.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_9717.The_Unbearable_Lightness_of_Being.html\n",
        "['01_2767052-the-hunger-games.html', '01_2.Harry_Potter_and_the_Order_of_the_Phoenix.html', '01_41865.Twilight.html', '01_2657.To_Kill_a_Mockingbird.html', '01_1885.Pride_and_Prejudice.html', '02_24583.The_Adventures_of_Tom_Sawyer.html', '02_34.The_Fellowship_of_the_Ring.html', '02_6310.Charlie_and_the_Chocolate_Factory.html', '02_4948.The_Very_Hungry_Caterpillar.html', '02_9717.The_Unbearable_Lightness_of_Being.html']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets parse each item we fetched. The code to get the year is complex..see the shakespeare case as to why. For now dont worry about understanding the else part: that is homework..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "yearre = r'\\d{4}'\n",
      "listofdicts=[]\n",
      "for filetoread in fetched:\n",
      "    td={}\n",
      "    d=pq(filename=filetoread)\n",
      "    td['title']=d(\"meta[property='og:title']\").attr('content')\n",
      "    td['isbn']=d(\"meta[property='good_reads:isbn']\").attr('content')\n",
      "    td['booktype']=d(\"meta[property='og:type']\").attr('content')\n",
      "    td['author']=d(\"meta[property='good_reads:author']\").attr('content')\n",
      "    td['rating']=d(\"span.average\").text()\n",
      "    td['ratingCount']=d(\"span.value-title[itemprop='ratingCount']\").attr(\"title\")\n",
      "    td['reviewCount']=d(\"span.value-title[itemprop!='ratingCount']\").attr(\"title\")\n",
      "    if d(\"nobr.greyText\").text().strip()!=\"\":\n",
      "        td['year']=d(\"nobr.greyText\").text().strip().split()[-1][:-1]\n",
      "    else:\n",
      "        thetext=d(\"div#details div.row\").eq(1).text().strip()\n",
      "        rowmatch=re.findall(yearre, thetext)\n",
      "        if len(rowmatch) > 0:\n",
      "            rowtext=rowmatch[0].strip()\n",
      "        else:\n",
      "            rowtext=\"NA\"\n",
      "        td['year']=rowtext\n",
      "    td['file']=filetoread\n",
      "    genres=d(\"div.elementList div.left a\")\n",
      "    glist=[]\n",
      "    for g in genres:\n",
      "        glist.append(d(g).attr('href'))\n",
      "    td['genres']=\"|\".join(glist)\n",
      "    listofdicts.append(td)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "listofdicts[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "{'author': 'https://www.goodreads.com/author/show/153394.Suzanne_Collins',\n",
        " 'booktype': 'good_reads:book',\n",
        " 'file': '01_2767052-the-hunger-games.html',\n",
        " 'genres': '/genres/young-adult|/genres/fiction|/genres/science-fiction|/genres/dystopia|/genres/fantasy|/genres/science-fiction|/genres/romance|/genres/adventure|/genres/book-club|/genres/young-adult|/genres/teen|/genres/apocalyptic|/genres/post-apocalyptic',\n",
        " 'isbn': '0439023483',\n",
        " 'rating': '4.40',\n",
        " 'ratingCount': '3011421',\n",
        " 'reviewCount': '137085',\n",
        " 'title': 'The Hunger Games (The Hunger Games, #1)',\n",
        " 'year': '2008'}"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally lets write all this stuff into a csv file which we will use to do analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "f = open('meta.csv','w')\n",
      "w = csv.DictWriter(f,listofdicts[0].keys())\n",
      "for i,D in enumerate(listofdicts):\n",
      "    listofdicts[i]={k:('None' if v==None else v.encode(\"utf-8\")) for k,v in D.items()}\n",
      "w.writerows(listofdicts)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Volume in drive C has no label.\n",
        " Volume Serial Number is A089-1276\n",
        "\n",
        " Directory of C:\\Users\\Zac Painter\\Documents\\IPython Notebooks\\dst4l3\\day3rahul\n",
        "\n",
        "11/08/2014  10:01 AM    <DIR>          .\n",
        "11/08/2014  10:01 AM    <DIR>          ..\n",
        "11/08/2014  10:01 AM    <DIR>          .ipynb_checkpoints\n",
        "11/08/2014  10:01 AM           452,200 01_1885.Pride_and_Prejudice.html\n",
        "11/08/2014  10:00 AM           502,956 01_2.Harry_Potter_and_the_Order_of_the_Phoenix.html\n",
        "11/08/2014  10:01 AM           556,721 01_2657.To_Kill_a_Mockingbird.html\n",
        "11/08/2014  10:00 AM           597,731 01_2767052-the-hunger-games.html\n",
        "11/08/2014  10:01 AM           598,025 01_41865.Twilight.html\n",
        "11/08/2014  10:01 AM           433,001 02_24583.The_Adventures_of_Tom_Sawyer.html\n",
        "11/08/2014  10:01 AM           512,146 02_34.The_Fellowship_of_the_Ring.html\n",
        "11/08/2014  10:01 AM           352,424 02_4948.The_Very_Hungry_Caterpillar.html\n",
        "11/08/2014  10:01 AM           434,531 02_6310.Charlie_and_the_Chocolate_Factory.html\n",
        "11/08/2014  10:01 AM           521,653 02_9717.The_Unbearable_Lightness_of_Being.html\n",
        "11/04/2014  04:02 PM         2,372,218 all.csv\n",
        "11/08/2014  10:20 AM            16,922 day3practice.ipynb\n",
        "11/08/2014  10:00 AM             3,660 list01.txt\n",
        "11/08/2014  10:00 AM             3,762 list02.txt\n",
        "11/08/2014  10:01 AM             4,128 meta.csv\n",
        "11/06/2014  06:03 PM         3,188,825 mycleaned.csv\n",
        "11/08/2014  09:59 AM           723,875 page01.html\n",
        "11/08/2014  10:00 AM           723,945 page02.html\n",
        "11/06/2014  06:04 PM           576,236 SpreadsheetsAreCutePandas.ipynb\n",
        "              19 File(s)     12,574,959 bytes\n",
        "               3 Dir(s)  449,433,440,256 bytes free\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}